{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Download the Brazilian coins dataset, adapted from [Kaggle -Ronaldo S Moura](https://www.kaggle.com/ronaldosm96/brazilian-coins-dataset) as a split in subdirectories for the coin classes."
      ],
      "metadata": {
        "id": "1zg0Ry64gxpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://edshare.gcu.ac.uk/id/document/61314 \\\n",
        "      -O /content/Brazilian_coins_dataset_ClassSplit.zip"
      ],
      "metadata": {
        "id": "jDWMo_ZpoRaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "916fbbc6-4bda-4488-a10f-4f93a98f3694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-25 20:48:26--  https://edshare.gcu.ac.uk/id/document/61314\n",
            "Resolving edshare.gcu.ac.uk (edshare.gcu.ac.uk)... 46.22.140.159\n",
            "Connecting to edshare.gcu.ac.uk (edshare.gcu.ac.uk)|46.22.140.159|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://edshare.gcu.ac.uk/9958/1/Brazilian_coins_dataset_ClassSplit.zip [following]\n",
            "--2025-03-25 20:48:27--  https://edshare.gcu.ac.uk/9958/1/Brazilian_coins_dataset_ClassSplit.zip\n",
            "Reusing existing connection to edshare.gcu.ac.uk:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33540668 (32M) [application/zip]\n",
            "Saving to: ‘/content/Brazilian_coins_dataset_ClassSplit.zip’\n",
            "\n",
            "/content/Brazilian_ 100%[===================>]  31.99M  10.7MB/s    in 3.0s    \n",
            "\n",
            "2025-03-25 20:48:30 (10.7 MB/s) - ‘/content/Brazilian_coins_dataset_ClassSplit.zip’ saved [33540668/33540668]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-qUPyfO7Qr8"
      },
      "source": [
        "The zip file is next extracted to the current directory, producing `train` and `validation` subdirectories. In turn each contains `005`, `010`,`025`,`050` and `100` subdirectories for each coin type (value in `centavos` of Brazilian real)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "#extract it. Directories structure as train/val is created\n",
        "local_zip = '/content/Brazilian_coins_dataset_ClassSplit.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('./')\n",
        "zip_ref.close()\n",
        "os.remove('./split_in_folders.c') #C code used to re-arrange the original images in subfolders"
      ],
      "metadata": {
        "id": "U292jInZkqVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define directories:"
      ],
      "metadata": {
        "id": "Xme87h8FuD0w"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLZKVtE0dSfk"
      },
      "source": [
        "base_dir = './'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3WZABE9eX-8"
      },
      "source": [
        "We have a total of 765 training images and 300 validation images. They look like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2_Q0-_5UAv-",
        "cellView": "form"
      },
      "source": [
        "#@title Show some coins\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "# Directory with our training 050 pictures\n",
        "train_050_dir = os.path.join(train_dir, '050')\n",
        "# Directory with our training 100 pictures\n",
        "train_100_dir = os.path.join(train_dir, '100')\n",
        "train_100_fnames = os.listdir(train_100_dir)\n",
        "train_050_fnames = os.listdir(train_050_dir)\n",
        "pic_index = 0 # Index for iterating over images\n",
        "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols * 4, nrows * 4)\n",
        "pic_index += 8\n",
        "next_100_pix = [os.path.join(train_100_dir, fname)\n",
        "                for fname in train_100_fnames[pic_index-8:pic_index]]\n",
        "next_050_pix = [os.path.join(train_050_dir, fname)\n",
        "                for fname in train_050_fnames[pic_index-8:pic_index]]\n",
        "for i, img_path in enumerate(next_100_pix+next_050_pix):\n",
        "  # Set up subplot; subplot indices start at 1\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off') # Don't show axes (or gridlines)\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oqBkNBJmtUv"
      },
      "source": [
        "## Building a Small Convnet from Scratch\n",
        "\n",
        "Resize all images to 100x100 pixels, so that will be the input size to the neural network.<p>\n",
        "Define a **shallow** network (there are few training examples, easy to overfit if too much capacity).<p>\n",
        "Notice that the actual purpose of the Conv layers is **extracting features to classify some coins** (we'll then do transfer learning for our UK coins). Define the final fully-connected layers in a separate step.<p>\n",
        "# From Keras.io\n",
        "You might wish to add regularization to some layers as well, to do so plesae check: https://keras.io/api/layers/regularizers/\n",
        "Regularizers allow you to apply penalties on layer parameters or layer activity during optimization. These penalties are summed into the loss function that the network optimizes.\n",
        "\n",
        "Regularization penalties are applied on a per-layer basis. The exact API will depend on the layer, but many layers (e.g. Dense, Conv1D, Conv2D and Conv3D) have a unified API.\n",
        "\n",
        "These layers expose 3 keyword arguments:\n",
        "\n",
        "    kernel_regularizer: Regularizer to apply a penalty on the layer's kernel\n",
        "    bias_regularizer: Regularizer to apply a penalty on the layer's bias\n",
        "    activity_regularizer: Regularizer to apply a penalty on the layer's output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clear Keras backend to try new model (Only do this if you want to change model parameters)\n",
        "\n"
      ],
      "metadata": {
        "id": "jJMYHIcSFvJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Clear the current TensorFlow graph\n",
        "K.clear_session()\n",
        "\n",
        "# Reinitialize your model from scratch\n",
        "model = None  # Explicitly set to None"
      ],
      "metadata": {
        "id": "Nb9Lc8cNF2JA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYVLSfbsbf9K"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import regularizers #for regularization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input feature map is 100x100x3 colour channels\n",
        "# img_input = layers.Input(shape=(100, 100, 3))\n",
        "# #ADD INTERMEDIATE CONV + POOLING LAYERS\n",
        "# #DON'T ADD FINAL LAYERS AT THIS STEP, USE THE NEXT ONE\n",
        "\n",
        "img_input = layers.Input(shape=(100, 100, 3))\n",
        "# Keep the training on only two layers to extract only generalized features like shapes and edges and such, prevent overfitting\n",
        "\n",
        "x = layers.Conv2D(16, (5, 5), activation='relu')(img_input) # first layer takes image in, finds features (16 filters/kernels)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu')(x)         # second layer looks at the output of first layer (32 filters)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "'''\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu')(x)         # 3rd layer as above 64 filters\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = layers.Conv2D(128, (3, 3), activation='relu')(x)         # 4th layer as above 128 filters\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "7lSf9CX4vJvB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2141a762-3450-4a4a-fce1-6654a4c8a54f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nx = layers.Conv2D(64, (3, 3), activation='relu')(x)         # 3rd layer as above 64 filters\\nx = layers.MaxPooling2D((2, 2))(x)\\n\\nx = layers.Conv2D(128, (3, 3), activation='relu')(x)         # 4th layer as above 128 filters\\nx = layers.MaxPooling2D((2, 2))(x)\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWO_RJpbsmVD"
      },
      "source": [
        "Now **flatten** the feature map and add a couple dense (fully connected) layers. The final one needs **5 outputs** as we're doing a 5-class classification.<p>\n",
        "<u>We can no longer use a sigmoid output</u> (that handles only 2 classes). See aother vailable activations in https://keras.io/api/layers/activations/\n",
        "You can add regularization, and also dropout right before the final layer to improve generalization (reduce overfitting)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Flatten feature map to a 1-dim tensor so we can add fully connected layers\n",
        "# #update x with the output name of the previous step if different\n",
        "# x = layers.Flatten()(x) # modify accordingly\n",
        "# # ADD HIDDEN AND FINAL DENSE LAYERS\n",
        "# # OUTPUT LAYERS NEEDS 5 NODES (one per class). 'sigmoid' ACTIVATION NO LONGER SUITABLE\n",
        "# # Create model:\n",
        "# model = Model(img_input, output)\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(64, activation='relu')(x) # reduce numper of neurons due to small network\n",
        "output = layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "# Create model:\n",
        "model = Model(img_input, output)\n"
      ],
      "metadata": {
        "id": "kTRMbVttvkSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9EaFDP5srBa"
      },
      "source": [
        "Let's summarize the model architecture. NOTICE THE LAYER NAMES, you'll need them later on:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZKj8392nbgP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "fb5ef28c-5589-49f8-be07-b252f17add14"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │           \u001b[38;5;34m1,216\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m4,640\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16928\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │       \u001b[38;5;34m1,083,456\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m325\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16928</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,083,456</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,089,637\u001b[0m (4.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,089,637</span> (4.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,089,637\u001b[0m (4.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,089,637</span> (4.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEkKSpZlvJXA"
      },
      "source": [
        "Next, we'll configure the specifications for model training, using Keras [model.compile](https://keras.io/api/models/model_training_apis/#compile-method) method.<p>\n",
        "Don't train our model with the `binary_crossentropy` loss, because the final activation cannot be a sigmoid. Check https://keras.io/api/losses/ for alternative **loss** metrics suitable for your new activation.<p>\n",
        "We can use RMSprop optimizer algorithm `rmsprop`, learning rate commonly 0.001. During training, we will want to monitor classification accuracy. Other available optimizers: https://keras.io/api/optimizers/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DHWhFP_uhq3"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "# use categorical crossentropy losss\n",
        "model.compile(loss='categorical_crossentropy', # Multi-class classification\n",
        "              optimizer=RMSprop(learning_rate=0.001),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn9m9D3UimHM"
      },
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "Let's set up data generators that will read pictures in our source folders, convert them to `float32` tensors, and feed them (with their labels 0, 1, 2, ... corresponding to each of the supplied subdirectories) to our network. As our data is split in train and validation folders, we need one generator for the training images and one for the validation images.<p>\n",
        "Our generators will yield batches of B images and their labels.<p>\n",
        "Preprocess the images by normalizing the pixel values to be in the `[0.0, 1.0]` range (dividing by 255.0). We can also benefit of **data augmentation** to account for more variability. Rotations are really important as new coins may appear rotated during future inference.<p>\n",
        "In Keras this can be done via the `keras.preprocessing.image.ImageDataGenerator` class. To find out more augmentation options, check https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator. <p>\n",
        "We also need to set class_mode to `categorical` (no longer `binary`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClebU9NJg99G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53e71416-aaa2-4e20-f514-d89e50892be7"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# All images will be rescaled by 1./255 and augmented\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,           # Artificially increase the dataset by modifying the training data as belo:\n",
        "      rotation_range=40,        #   Allow the NN to train on coins that are at different angles\n",
        "      width_shift_range=0.2,    #   This helps the model learn to recognize coins even if they are not perfectly centered in the image.\n",
        "      height_shift_range=0.2,   #   As above but vertically\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')      # fill empty pixels created after the shifts above with a copy of nearest pixel\n",
        "val_datagen = ImageDataGenerator(rescale=1./255) #do not augment validation\n",
        "B = 15 #Batch size\n",
        "# Flow training images in batches of B using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,  # This is the source directory for training images\n",
        "        target_size = (100, 100),  # All images will be resized to 100x100\n",
        "        batch_size=B,\n",
        "        # To use categorical_crossentropy loss, we need categorical labels\n",
        "        class_mode='categorical')\n",
        "# Flow validation images in batches of 20 using val_datagen generator\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(100, 100),\n",
        "        batch_size=B,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 765 images belonging to 5 classes.\n",
            "Found 300 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu3Jdwkjwax4"
      },
      "source": [
        "### Training\n",
        "Let's train on all 765 images available, for 15 epochs, and validate on all 300 validation images. (This may take a few minutes to run).<p>\n",
        "If the training accuracy is significantly better than validation accuracy, the model is overfitting, you should include regularization and dropout.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb1_lgobv81m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d8682f5-424e-4850-a282-0fa00671c749"
      },
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=765//B,  # 765 images = batch_size * steps\n",
        "      epochs=20,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=300//B,  # 300 images = batch_size * steps\n",
        "      verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "51/51 - 8s - 156ms/step - acc: 0.3020 - loss: 1.6587 - val_acc: 0.4333 - val_loss: 1.4027\n",
            "Epoch 2/20\n",
            "51/51 - 6s - 117ms/step - acc: 0.4340 - loss: 1.4040 - val_acc: 0.2300 - val_loss: 1.9767\n",
            "Epoch 3/20\n",
            "51/51 - 5s - 104ms/step - acc: 0.4954 - loss: 1.2524 - val_acc: 0.5133 - val_loss: 1.0745\n",
            "Epoch 4/20\n",
            "51/51 - 5s - 95ms/step - acc: 0.5190 - loss: 1.0940 - val_acc: 0.7233 - val_loss: 0.8702\n",
            "Epoch 5/20\n",
            "51/51 - 6s - 117ms/step - acc: 0.6013 - loss: 0.9910 - val_acc: 0.6633 - val_loss: 0.7251\n",
            "Epoch 6/20\n",
            "51/51 - 4s - 82ms/step - acc: 0.6052 - loss: 0.9400 - val_acc: 0.6967 - val_loss: 0.7808\n",
            "Epoch 7/20\n",
            "51/51 - 3s - 55ms/step - acc: 0.6288 - loss: 0.8739 - val_acc: 0.6900 - val_loss: 0.7483\n",
            "Epoch 8/20\n",
            "51/51 - 3s - 68ms/step - acc: 0.6353 - loss: 0.8467 - val_acc: 0.7567 - val_loss: 0.6416\n",
            "Epoch 9/20\n",
            "51/51 - 4s - 87ms/step - acc: 0.6889 - loss: 0.7677 - val_acc: 0.6600 - val_loss: 0.9612\n",
            "Epoch 10/20\n",
            "51/51 - 3s - 55ms/step - acc: 0.6771 - loss: 0.7764 - val_acc: 0.6867 - val_loss: 0.7522\n",
            "Epoch 11/20\n",
            "51/51 - 3s - 54ms/step - acc: 0.7190 - loss: 0.7126 - val_acc: 0.7233 - val_loss: 0.6285\n",
            "Epoch 12/20\n",
            "51/51 - 4s - 71ms/step - acc: 0.7059 - loss: 0.6818 - val_acc: 0.8400 - val_loss: 0.5335\n",
            "Epoch 13/20\n",
            "51/51 - 3s - 55ms/step - acc: 0.7229 - loss: 0.6886 - val_acc: 0.8100 - val_loss: 0.5618\n",
            "Epoch 14/20\n",
            "51/51 - 5s - 106ms/step - acc: 0.7373 - loss: 0.6433 - val_acc: 0.6733 - val_loss: 0.7333\n",
            "Epoch 15/20\n",
            "51/51 - 4s - 72ms/step - acc: 0.7529 - loss: 0.6456 - val_acc: 0.8500 - val_loss: 0.4339\n",
            "Epoch 16/20\n",
            "51/51 - 3s - 56ms/step - acc: 0.7556 - loss: 0.6209 - val_acc: 0.7333 - val_loss: 0.6735\n",
            "Epoch 17/20\n",
            "51/51 - 5s - 104ms/step - acc: 0.7438 - loss: 0.5955 - val_acc: 0.7467 - val_loss: 0.4699\n",
            "Epoch 18/20\n",
            "51/51 - 4s - 72ms/step - acc: 0.7660 - loss: 0.5712 - val_acc: 0.8000 - val_loss: 0.4377\n",
            "Epoch 19/20\n",
            "51/51 - 5s - 89ms/step - acc: 0.7647 - loss: 0.5953 - val_acc: 0.8233 - val_loss: 0.4237\n",
            "Epoch 20/20\n",
            "51/51 - 3s - 53ms/step - acc: 0.7621 - loss: 0.5699 - val_acc: 0.8233 - val_loss: 0.4857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "XJulmxp_BN4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now let's transfer this to our UK coins\n",
        "We have a very limited collecton of UK coin examples (slightly above 300) split in 8 subdirectories, one for each  class. Let's apply transfer learning from our Brazilian coins."
      ],
      "metadata": {
        "id": "S18pw6zbQs9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://edshare.gcu.ac.uk/id/document/61325 \\\n",
        "      -O /content/UK_coins_ClassSplit.zip"
      ],
      "metadata": {
        "id": "Nc7wwYWmQsOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b6514d-9fc2-49d2-918a-519e22dc0810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-25 21:09:09--  https://edshare.gcu.ac.uk/id/document/61325\n",
            "Resolving edshare.gcu.ac.uk (edshare.gcu.ac.uk)... 46.22.140.159\n",
            "Connecting to edshare.gcu.ac.uk (edshare.gcu.ac.uk)|46.22.140.159|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://edshare.gcu.ac.uk/9959/1/UK_coins_Mario_ClassSplit.zip [following]\n",
            "--2025-03-25 21:09:10--  https://edshare.gcu.ac.uk/9959/1/UK_coins_Mario_ClassSplit.zip\n",
            "Reusing existing connection to edshare.gcu.ac.uk:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2212692 (2.1M) [application/zip]\n",
            "Saving to: ‘/content/UK_coins_ClassSplit.zip’\n",
            "\n",
            "/content/UK_coins_C 100%[===================>]   2.11M  1.83MB/s    in 1.2s    \n",
            "\n",
            "2025-03-25 21:09:12 (1.83 MB/s) - ‘/content/UK_coins_ClassSplit.zip’ saved [2212692/2212692]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_zip = '/content/UK_coins_ClassSplit.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('./')\n",
        "zip_ref.close()\n",
        "UK_base_dir = './UK_coins_Mario_ClassSplit'"
      ],
      "metadata": {
        "id": "SII_ob6FUUMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a look to some UK coin images:"
      ],
      "metadata": {
        "id": "zFcaWLCecUPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Show some coins\n",
        "UK_100_dir = os.path.join(UK_base_dir, '100')\n",
        "UK_050_dir = os.path.join(UK_base_dir, '050')\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "train_100_fnames = os.listdir(UK_100_dir)\n",
        "train_050_fnames = os.listdir(UK_050_dir)\n",
        "pic_index = 0 # Index for iterating over images\n",
        "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols * 4, nrows * 4)\n",
        "pic_index += 8\n",
        "next_100_pix = [os.path.join(UK_100_dir, fname)\n",
        "                for fname in train_100_fnames[pic_index-8:pic_index]]\n",
        "next_050_pix = [os.path.join(UK_050_dir, fname)\n",
        "                for fname in train_050_fnames[pic_index-8:pic_index]]\n",
        "for i, img_path in enumerate(next_100_pix+next_050_pix):\n",
        "  # Set up subplot; subplot indices start at 1\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off') # Don't show axes (or gridlines)\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rDOJvKYjcVad",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the training data. Notice that this time the data is not pre-split in \"train\" and \"validation\" directories. We can do an automatic train/validation split as determined by parameter `validation_split`.<p>"
      ],
      "metadata": {
        "id": "RKgXddMzZfhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# All images will be rescaled by 1./255 and augmented\n",
        "UK_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                rotation_range=90, #degrees\n",
        "                                validation_split=0.2)  #makes random split, 20% for validation\n",
        "B = 10 #Batch size\n",
        "# Extract flow training images in batches of B images\n",
        "UK_train_generator = UK_datagen.flow_from_directory(\n",
        "        UK_base_dir,  # This is the source directory for training images\n",
        "        target_size = (100, 100),  # All images will be resized to 100x100\n",
        "        batch_size=B,\n",
        "        subset = 'training',\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='categorical')\n",
        "# Extract flow validation images in batches of B images\n",
        "UK_validation_generator = UK_datagen.flow_from_directory(\n",
        "        UK_base_dir,\n",
        "        target_size=(100, 100),\n",
        "        batch_size=B,\n",
        "        subset = 'validation',\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "JJUqFresZaYA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4760775a-0dae-4017-d1fc-d705a3e1752c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 250 images belonging to 8 classes.\n",
            "Found 59 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we freeze all layers of our Brazilian CNN, so they don't get re-trained:"
      ],
      "metadata": {
        "id": "LzD98-15fqTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "  print('freezing ' + layer.name)\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "ltW3agGuf02w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ed24cf2-82f4-4910-8dc7-b4266c06e8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "freezing input_layer\n",
            "freezing conv2d\n",
            "freezing max_pooling2d\n",
            "freezing conv2d_1\n",
            "freezing max_pooling2d_1\n",
            "freezing flatten\n",
            "freezing dense\n",
            "freezing dense_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, replace the last FC layers (right after flattening) by new ones. **Output now needs 8 classes!**<p>\n",
        "Check the layer names to select the desired replacement point."
      ],
      "metadata": {
        "id": "UNdN9mvPh6cX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "replace_point = model.get_layer('flatten')\n",
        "x = replace_point.output\n",
        "#x = layers.Dense(128, activation='relu')(x) # 256 might be too many neurons\n",
        "x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x) # reduce from 128\n",
        "x = layers.Dropout(0.6)(x)                  #  prevent overfitting with a dropout\n",
        "UKoutput = layers.Dense(8, activation='softmax')(x)\n",
        "\n",
        "UKmodel = Model(img_input, UKoutput)"
      ],
      "metadata": {
        "id": "fxH5ot0BiNVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get a summary of the updated  UK model. Is should show a number of non-trainable parameters (those from the frozen layers). The transferred layers should have the same names they had in the original model, added layers will get new names."
      ],
      "metadata": {
        "id": "DuAzWq0Vjdxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UKmodel.summary()"
      ],
      "metadata": {
        "id": "pA8ImLTIiuf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "7dadbcd5-a5e5-4204-a20a-5132fdc7bd84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │           \u001b[38;5;34m1,216\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m4,640\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16928\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │       \u001b[38;5;34m1,083,456\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16928</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,083,456</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,089,832\u001b[0m (4.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,089,832</span> (4.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,083,976\u001b[0m (4.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,083,976</span> (4.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,856\u001b[0m (22.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,856</span> (22.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the new model. Remember that we need to use a reduced learning rate (like 1/10 of the original one)"
      ],
      "metadata": {
        "id": "AhMbm-GUjZE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UKmodel.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=0.0001), # Reduced learning rate\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "rtdT4I1ZjOVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the added layers on our UK coins. We are assuming that the Brazilian coin features extracted by the frozen layers will also be useful for the UK coins..."
      ],
      "metadata": {
        "id": "hP9Jikv6kBqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = UKmodel.fit(\n",
        "      UK_train_generator,\n",
        "      steps_per_epoch=250//B,  # 250 train images = batch_size * steps\n",
        "      epochs=40,\n",
        "      validation_data=UK_validation_generator,\n",
        "      validation_steps=59//B,  # 59 validation images = batch_size * steps\n",
        "      verbose=2)"
      ],
      "metadata": {
        "id": "fM52371kkQb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a9d2d4-75b1-42dc-90a4-9a32f217704e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "25/25 - 4s - 166ms/step - acc: 0.2000 - loss: 2.1183 - val_acc: 0.4000 - val_loss: 1.9884\n",
            "Epoch 2/40\n",
            "25/25 - 1s - 34ms/step - acc: 0.2880 - loss: 1.9580 - val_acc: 0.4200 - val_loss: 1.8445\n",
            "Epoch 3/40\n",
            "25/25 - 1s - 34ms/step - acc: 0.3240 - loss: 1.8484 - val_acc: 0.4600 - val_loss: 1.7621\n",
            "Epoch 4/40\n",
            "25/25 - 1s - 33ms/step - acc: 0.3840 - loss: 1.7704 - val_acc: 0.4600 - val_loss: 1.7548\n",
            "Epoch 5/40\n",
            "25/25 - 1s - 33ms/step - acc: 0.3200 - loss: 1.7696 - val_acc: 0.4000 - val_loss: 1.7044\n",
            "Epoch 6/40\n",
            "25/25 - 1s - 33ms/step - acc: 0.3080 - loss: 1.7616 - val_acc: 0.4400 - val_loss: 1.6269\n",
            "Epoch 7/40\n",
            "25/25 - 1s - 33ms/step - acc: 0.3760 - loss: 1.6574 - val_acc: 0.4200 - val_loss: 1.5609\n",
            "Epoch 8/40\n",
            "25/25 - 1s - 50ms/step - acc: 0.3600 - loss: 1.6339 - val_acc: 0.4600 - val_loss: 1.5353\n",
            "Epoch 9/40\n",
            "25/25 - 1s - 33ms/step - acc: 0.4360 - loss: 1.5802 - val_acc: 0.4600 - val_loss: 1.5085\n",
            "Epoch 10/40\n",
            "25/25 - 1s - 33ms/step - acc: 0.4120 - loss: 1.5492 - val_acc: 0.4600 - val_loss: 1.4428\n",
            "Epoch 11/40\n",
            "25/25 - 1s - 34ms/step - acc: 0.4080 - loss: 1.5579 - val_acc: 0.4600 - val_loss: 1.4738\n",
            "Epoch 12/40\n",
            "25/25 - 3s - 102ms/step - acc: 0.4840 - loss: 1.4857 - val_acc: 0.5000 - val_loss: 1.3990\n",
            "Epoch 13/40\n",
            "25/25 - 1s - 34ms/step - acc: 0.4120 - loss: 1.5023 - val_acc: 0.4800 - val_loss: 1.4400\n",
            "Epoch 14/40\n",
            "25/25 - 1s - 49ms/step - acc: 0.4640 - loss: 1.4797 - val_acc: 0.5000 - val_loss: 1.3682\n",
            "Epoch 15/40\n",
            "25/25 - 1s - 33ms/step - acc: 0.4120 - loss: 1.5055 - val_acc: 0.5600 - val_loss: 1.3811\n",
            "Epoch 16/40\n",
            "25/25 - 1s - 34ms/step - acc: 0.4560 - loss: 1.4543 - val_acc: 0.6400 - val_loss: 1.3516\n",
            "Epoch 17/40\n",
            "25/25 - 1s - 36ms/step - acc: 0.4720 - loss: 1.4640 - val_acc: 0.6400 - val_loss: 1.3358\n",
            "Epoch 18/40\n",
            "25/25 - 1s - 48ms/step - acc: 0.5120 - loss: 1.3872 - val_acc: 0.5800 - val_loss: 1.3482\n",
            "Epoch 19/40\n",
            "25/25 - 1s - 48ms/step - acc: 0.5040 - loss: 1.3978 - val_acc: 0.5800 - val_loss: 1.3047\n",
            "Epoch 20/40\n",
            "25/25 - 1s - 50ms/step - acc: 0.5080 - loss: 1.3437 - val_acc: 0.6200 - val_loss: 1.2554\n",
            "Epoch 21/40\n",
            "25/25 - 1s - 34ms/step - acc: 0.5640 - loss: 1.3856 - val_acc: 0.6800 - val_loss: 1.2525\n",
            "Epoch 22/40\n",
            "25/25 - 1s - 54ms/step - acc: 0.5600 - loss: 1.3207 - val_acc: 0.6200 - val_loss: 1.2814\n",
            "Epoch 23/40\n",
            "25/25 - 1s - 53ms/step - acc: 0.5160 - loss: 1.3591 - val_acc: 0.5800 - val_loss: 1.2893\n",
            "Epoch 24/40\n",
            "25/25 - 1s - 34ms/step - acc: 0.5160 - loss: 1.3468 - val_acc: 0.5800 - val_loss: 1.2662\n",
            "Epoch 25/40\n",
            "25/25 - 1s - 33ms/step - acc: 0.4840 - loss: 1.3550 - val_acc: 0.7200 - val_loss: 1.2018\n",
            "Epoch 26/40\n",
            "25/25 - 1s - 50ms/step - acc: 0.5160 - loss: 1.2709 - val_acc: 0.5800 - val_loss: 1.2696\n",
            "Epoch 27/40\n",
            "25/25 - 1s - 34ms/step - acc: 0.5400 - loss: 1.2730 - val_acc: 0.5800 - val_loss: 1.2429\n",
            "Epoch 28/40\n",
            "25/25 - 1s - 33ms/step - acc: 0.5560 - loss: 1.2306 - val_acc: 0.6600 - val_loss: 1.2542\n",
            "Epoch 29/40\n",
            "25/25 - 1s - 51ms/step - acc: 0.5120 - loss: 1.2724 - val_acc: 0.6600 - val_loss: 1.1686\n",
            "Epoch 30/40\n",
            "25/25 - 1s - 49ms/step - acc: 0.5600 - loss: 1.2379 - val_acc: 0.6600 - val_loss: 1.2323\n",
            "Epoch 31/40\n",
            "25/25 - 1s - 33ms/step - acc: 0.5640 - loss: 1.2636 - val_acc: 0.6200 - val_loss: 1.1856\n",
            "Epoch 32/40\n",
            "25/25 - 1s - 49ms/step - acc: 0.5480 - loss: 1.2471 - val_acc: 0.6600 - val_loss: 1.1395\n",
            "Epoch 33/40\n",
            "25/25 - 1s - 43ms/step - acc: 0.5240 - loss: 1.2344 - val_acc: 0.7200 - val_loss: 1.1076\n",
            "Epoch 34/40\n",
            "25/25 - 2s - 99ms/step - acc: 0.5640 - loss: 1.2034 - val_acc: 0.7000 - val_loss: 1.1767\n",
            "Epoch 35/40\n",
            "25/25 - 1s - 50ms/step - acc: 0.5760 - loss: 1.2344 - val_acc: 0.6400 - val_loss: 1.2046\n",
            "Epoch 36/40\n",
            "25/25 - 1s - 33ms/step - acc: 0.5280 - loss: 1.2086 - val_acc: 0.6800 - val_loss: 1.0672\n",
            "Epoch 37/40\n",
            "25/25 - 1s - 34ms/step - acc: 0.5480 - loss: 1.2310 - val_acc: 0.6600 - val_loss: 1.1092\n",
            "Epoch 38/40\n",
            "25/25 - 1s - 50ms/step - acc: 0.5560 - loss: 1.1804 - val_acc: 0.6200 - val_loss: 1.0993\n",
            "Epoch 39/40\n",
            "25/25 - 1s - 33ms/step - acc: 0.5440 - loss: 1.2393 - val_acc: 0.6400 - val_loss: 1.1324\n",
            "Epoch 40/40\n",
            "25/25 - 1s - 50ms/step - acc: 0.5680 - loss: 1.1843 - val_acc: 0.6400 - val_loss: 1.1742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You might try to improve a bit by unfreezing the last imported Conv layer as well, and retrain some more with a heavily reduced learning rate (1/100 of the original)<p>\n",
        "Check the layers names and update them as needed."
      ],
      "metadata": {
        "id": "fYdFEBXRnJme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unfreeze = False\n",
        "for layer in UKmodel.layers:\n",
        "  if layer.name == 'conv2d_1': #first layer to unfreeze\n",
        "    print('--- unfreezing ---')\n",
        "    unfreeze = True\n",
        "  if unfreeze:\n",
        "    layer.trainable = True\n",
        "  print(layer.name)"
      ],
      "metadata": {
        "id": "98S04Tc0nOqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a66673c-b31d-4b6a-8643-a015980b894d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_layer\n",
            "conv2d\n",
            "max_pooling2d\n",
            "--- unfreezing ---\n",
            "conv2d_1\n",
            "max_pooling2d_1\n",
            "flatten\n",
            "dense_2\n",
            "dropout\n",
            "dense_3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#show model again. Compare thenumber of non-trainable parameters with previous versions\n",
        "UKmodel.summary()"
      ],
      "metadata": {
        "id": "s6mltjmws6yt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "f8e5309b-12de-429f-c4ef-6a8d07ed3f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │           \u001b[38;5;34m1,216\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m4,640\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16928\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │       \u001b[38;5;34m1,083,456\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16928</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,083,456</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,173,810\u001b[0m (8.29 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,173,810</span> (8.29 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,088,616\u001b[0m (4.15 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,088,616</span> (4.15 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,216\u001b[0m (4.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> (4.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,083,978\u001b[0m (4.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,083,978</span> (4.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, fine-tune with Stochastic Gradient Descent with very low learning rate for 50 epochs"
      ],
      "metadata": {
        "id": "8dPM4eq778yD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# As an optimizer, here we will use SGD\n",
        "# with a very low learning rate (0.00001)\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "UKmodel.compile(loss='categorical_crossentropy',\n",
        "                optimizer=SGD(learning_rate=0.001/100, momentum=0.9),\n",
        "                metrics=['acc'])"
      ],
      "metadata": {
        "id": "cS2i2zEpmIYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = UKmodel.fit(\n",
        "      UK_train_generator,\n",
        "      steps_per_epoch=250//B,  # 221 images = batch_size * steps\n",
        "      epochs=50,\n",
        "      validation_data=UK_validation_generator,\n",
        "      validation_steps=59//B,  # 88 images = batch_size * steps\n",
        "      verbose=2)"
      ],
      "metadata": {
        "id": "L2tb_E8onW2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b52c0d4-a00f-45c4-f78a-27daa6e9286c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "25/25 - 3s - 129ms/step - acc: 0.6240 - loss: 1.1464 - val_acc: 0.5800 - val_loss: 1.1673\n",
            "Epoch 2/50\n",
            "25/25 - 1s - 36ms/step - acc: 0.5920 - loss: 1.1123 - val_acc: 0.6200 - val_loss: 1.1264\n",
            "Epoch 3/50\n",
            "25/25 - 1s - 50ms/step - acc: 0.6080 - loss: 1.1562 - val_acc: 0.6200 - val_loss: 1.1136\n",
            "Epoch 4/50\n",
            "25/25 - 1s - 34ms/step - acc: 0.5880 - loss: 1.1554 - val_acc: 0.6800 - val_loss: 1.1001\n",
            "Epoch 5/50\n",
            "25/25 - 1s - 54ms/step - acc: 0.6280 - loss: 1.0905 - val_acc: 0.6600 - val_loss: 1.0894\n",
            "Epoch 6/50\n",
            "25/25 - 2s - 81ms/step - acc: 0.5680 - loss: 1.1072 - val_acc: 0.6000 - val_loss: 1.1392\n",
            "Epoch 7/50\n",
            "25/25 - 1s - 49ms/step - acc: 0.5720 - loss: 1.1956 - val_acc: 0.6600 - val_loss: 1.1317\n",
            "Epoch 8/50\n",
            "25/25 - 1s - 51ms/step - acc: 0.5640 - loss: 1.1749 - val_acc: 0.5600 - val_loss: 1.1973\n",
            "Epoch 9/50\n",
            "25/25 - 1s - 34ms/step - acc: 0.5800 - loss: 1.1354 - val_acc: 0.6600 - val_loss: 1.1254\n",
            "Epoch 10/50\n",
            "25/25 - 1s - 33ms/step - acc: 0.5840 - loss: 1.1450 - val_acc: 0.6000 - val_loss: 1.1551\n",
            "Epoch 11/50\n",
            "25/25 - 1s - 33ms/step - acc: 0.6160 - loss: 1.1573 - val_acc: 0.6400 - val_loss: 1.1244\n",
            "Epoch 12/50\n",
            "25/25 - 1s - 53ms/step - acc: 0.6120 - loss: 1.1293 - val_acc: 0.7200 - val_loss: 1.0891\n",
            "Epoch 13/50\n",
            "25/25 - 1s - 48ms/step - acc: 0.5720 - loss: 1.2381 - val_acc: 0.6400 - val_loss: 1.1190\n",
            "Epoch 14/50\n",
            "25/25 - 1s - 34ms/step - acc: 0.5680 - loss: 1.1497 - val_acc: 0.6600 - val_loss: 1.1532\n",
            "Epoch 15/50\n",
            "25/25 - 3s - 101ms/step - acc: 0.5960 - loss: 1.1202 - val_acc: 0.6600 - val_loss: 1.1552\n",
            "Epoch 16/50\n",
            "25/25 - 1s - 34ms/step - acc: 0.6240 - loss: 1.1054 - val_acc: 0.6600 - val_loss: 1.1659\n",
            "Epoch 17/50\n",
            "25/25 - 1s - 33ms/step - acc: 0.5880 - loss: 1.1687 - val_acc: 0.6600 - val_loss: 1.0957\n",
            "Epoch 18/50\n",
            "25/25 - 1s - 50ms/step - acc: 0.6000 - loss: 1.1378 - val_acc: 0.5800 - val_loss: 1.1506\n",
            "Epoch 19/50\n",
            "25/25 - 1s - 50ms/step - acc: 0.5760 - loss: 1.1440 - val_acc: 0.6400 - val_loss: 1.1258\n",
            "Epoch 20/50\n",
            "25/25 - 1s - 51ms/step - acc: 0.5880 - loss: 1.1329 - val_acc: 0.5800 - val_loss: 1.1698\n",
            "Epoch 21/50\n",
            "25/25 - 1s - 34ms/step - acc: 0.5800 - loss: 1.1503 - val_acc: 0.7000 - val_loss: 1.0817\n",
            "Epoch 22/50\n",
            "25/25 - 1s - 49ms/step - acc: 0.6160 - loss: 1.1047 - val_acc: 0.7600 - val_loss: 0.9768\n",
            "Epoch 23/50\n",
            "25/25 - 1s - 51ms/step - acc: 0.6040 - loss: 1.1180 - val_acc: 0.6600 - val_loss: 1.1577\n",
            "Epoch 24/50\n",
            "25/25 - 2s - 69ms/step - acc: 0.6400 - loss: 1.0868 - val_acc: 0.6400 - val_loss: 1.1137\n",
            "Epoch 25/50\n",
            "25/25 - 2s - 82ms/step - acc: 0.6120 - loss: 1.1064 - val_acc: 0.6400 - val_loss: 1.1174\n",
            "Epoch 26/50\n",
            "25/25 - 1s - 33ms/step - acc: 0.6040 - loss: 1.1315 - val_acc: 0.6600 - val_loss: 1.0980\n",
            "Epoch 27/50\n",
            "25/25 - 1s - 33ms/step - acc: 0.6120 - loss: 1.1209 - val_acc: 0.6800 - val_loss: 1.1118\n",
            "Epoch 28/50\n",
            "25/25 - 1s - 33ms/step - acc: 0.5720 - loss: 1.1364 - val_acc: 0.7000 - val_loss: 1.0488\n",
            "Epoch 29/50\n",
            "25/25 - 1s - 35ms/step - acc: 0.5960 - loss: 1.1379 - val_acc: 0.6800 - val_loss: 1.1438\n",
            "Epoch 30/50\n",
            "25/25 - 1s - 33ms/step - acc: 0.6120 - loss: 1.0962 - val_acc: 0.7000 - val_loss: 1.0751\n",
            "Epoch 31/50\n",
            "25/25 - 1s - 51ms/step - acc: 0.6400 - loss: 1.1146 - val_acc: 0.6600 - val_loss: 1.1180\n",
            "Epoch 32/50\n",
            "25/25 - 1s - 49ms/step - acc: 0.6160 - loss: 1.0988 - val_acc: 0.6600 - val_loss: 1.0376\n",
            "Epoch 33/50\n",
            "25/25 - 1s - 34ms/step - acc: 0.6000 - loss: 1.1233 - val_acc: 0.6600 - val_loss: 1.0101\n",
            "Epoch 34/50\n",
            "25/25 - 1s - 55ms/step - acc: 0.6280 - loss: 1.0853 - val_acc: 0.7000 - val_loss: 1.0261\n",
            "Epoch 35/50\n",
            "25/25 - 2s - 61ms/step - acc: 0.5440 - loss: 1.1341 - val_acc: 0.6600 - val_loss: 1.0870\n",
            "Epoch 36/50\n",
            "25/25 - 1s - 39ms/step - acc: 0.5800 - loss: 1.1562 - val_acc: 0.6600 - val_loss: 1.0742\n",
            "Epoch 37/50\n",
            "25/25 - 1s - 37ms/step - acc: 0.6360 - loss: 1.0691 - val_acc: 0.7000 - val_loss: 1.0949\n",
            "Epoch 38/50\n",
            "25/25 - 1s - 34ms/step - acc: 0.6440 - loss: 1.0392 - val_acc: 0.7000 - val_loss: 1.0701\n",
            "Epoch 39/50\n",
            "25/25 - 1s - 51ms/step - acc: 0.6400 - loss: 1.0786 - val_acc: 0.6200 - val_loss: 1.1505\n",
            "Epoch 40/50\n",
            "25/25 - 1s - 50ms/step - acc: 0.6400 - loss: 1.0673 - val_acc: 0.6800 - val_loss: 1.1087\n",
            "Epoch 41/50\n",
            "25/25 - 1s - 51ms/step - acc: 0.6000 - loss: 1.1454 - val_acc: 0.6800 - val_loss: 1.0880\n",
            "Epoch 42/50\n",
            "25/25 - 1s - 49ms/step - acc: 0.6160 - loss: 1.1325 - val_acc: 0.7200 - val_loss: 1.0069\n",
            "Epoch 43/50\n",
            "25/25 - 1s - 49ms/step - acc: 0.6280 - loss: 1.1271 - val_acc: 0.6800 - val_loss: 1.0787\n",
            "Epoch 44/50\n",
            "25/25 - 1s - 34ms/step - acc: 0.5840 - loss: 1.1434 - val_acc: 0.7600 - val_loss: 1.0170\n",
            "Epoch 45/50\n",
            "25/25 - 3s - 102ms/step - acc: 0.5760 - loss: 1.0881 - val_acc: 0.6600 - val_loss: 1.1809\n",
            "Epoch 46/50\n",
            "25/25 - 1s - 50ms/step - acc: 0.6200 - loss: 1.0947 - val_acc: 0.6600 - val_loss: 1.1464\n",
            "Epoch 47/50\n",
            "25/25 - 1s - 34ms/step - acc: 0.5960 - loss: 1.1298 - val_acc: 0.6800 - val_loss: 1.1039\n",
            "Epoch 48/50\n",
            "25/25 - 1s - 34ms/step - acc: 0.6000 - loss: 1.1228 - val_acc: 0.7000 - val_loss: 1.0902\n",
            "Epoch 49/50\n",
            "25/25 - 1s - 34ms/step - acc: 0.5800 - loss: 1.1556 - val_acc: 0.6800 - val_loss: 1.1296\n",
            "Epoch 50/50\n",
            "25/25 - 1s - 34ms/step - acc: 0.6040 - loss: 1.1069 - val_acc: 0.7000 - val_loss: 1.0792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuOYlmjYwKAN"
      },
      "source": [
        "# Inference\n",
        "That should be the classifier ready. If you wish, try to play inference on a new image using UKmodel.predict\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E8W5k3FwO-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d63fc7e2-02f6-46b5-c7fa-cfe507235a67"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "#upload a new coin image and try to classify it\n",
        "fname = \"./200_hard_065.jpg\" #update name as needed\n",
        "img = load_img(fname, target_size=(100, 100))\n",
        "x = img_to_array(img)  # Numpy array with shape (100, 100, 3)\n",
        "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 100, 100, 3)\n",
        "# Rescale by 1/255\n",
        "x /= 255\n",
        "# Let's run our image through our network\n",
        "prediction = UKmodel.predict(x)\n",
        "prediction\n",
        "#class numbers corresponds to subdirectories (train_datagen.flow_from_directory uses alphabetic order by default)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00181983, 0.00377008, 0.00803804, 0.00350178, 0.00106717,\n",
              "        0.01290081, 0.19587043, 0.7730319 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, print out the class indices to understand which index corresponds to which coin value:\n",
        "print(UK_train_generator.class_indices)\n",
        "# Find the index of the highest confidence prediction\n",
        "predicted_class_index = np.argmax(prediction)\n",
        "print(f\"Predicted class index: {predicted_class_index}\")\n",
        "# Convert the raw prediction to a more readable format:\n",
        "print(\"Prediction probabilities:\")\n",
        "for class_name, prob in zip(UK_train_generator.class_indices.keys(), prediction[0]):\n",
        "    print(f\"{class_name}: {prob:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDszNwjTlCzp",
        "outputId": "0408bda2-5659-4b57-d7dd-5a88861e8fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'001': 0, '002': 1, '005': 2, '010': 3, '020': 4, '050': 5, '100': 6, '200': 7}\n",
            "Predicted class index: 7\n",
            "Prediction probabilities:\n",
            "001: 0.0018\n",
            "002: 0.0038\n",
            "005: 0.0080\n",
            "010: 0.0035\n",
            "020: 0.0011\n",
            "050: 0.0129\n",
            "100: 0.1959\n",
            "200: 0.7730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Following code is for Pool Size calculation"
      ],
      "metadata": {
        "id": "UV9nLETQMfhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pool size calculation\n",
        "# Initial input size\n",
        "input_size = 100  # original input image size\n",
        "\n",
        "# For a 3x3 Conv2D with no padding\n",
        "def calculate_conv_output(input_size, kernel_size=3, stride=1):\n",
        "    return (input_size - kernel_size + 1) // stride\n",
        "\n",
        "# For a 2x2 MaxPooling2D\n",
        "def calculate_pool_output(input_size, pool_size=2, stride=2):\n",
        "    return input_size // pool_size\n",
        "\n",
        "# Example calculation\n",
        "current_size = 100\n",
        "print(\"Starting size:\", current_size)\n",
        "\n",
        "# First Conv2D + MaxPool\n",
        "current_size = calculate_pool_output(calculate_conv_output(current_size, kernel_size=5))\n",
        "print(\"After first layer:\", current_size)\n",
        "\n",
        "# Second Conv2D + MaxPool\n",
        "current_size = calculate_pool_output(calculate_conv_output(current_size))\n",
        "print(\"After second layer:\", current_size)\n",
        "\n",
        "# 3rd Conv2D + MaxPool\n",
        "current_size = calculate_pool_output(calculate_conv_output(current_size))\n",
        "print(\"After 3rd layer:\", current_size)\n",
        "\n",
        "# 4th Conv2D + MaxPool\n",
        "current_size = calculate_pool_output(calculate_conv_output(current_size))\n",
        "print(\"After 4th layer:\", current_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrZaIDV5Ews_",
        "outputId": "0dcc61b2-89be-46d1-a2e7-2f1d631420a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting size: 100\n",
            "After first layer: 48\n",
            "After second layer: 23\n",
            "After 3rd layer: 10\n",
            "After 4th layer: 4\n"
          ]
        }
      ]
    }
  ]
}